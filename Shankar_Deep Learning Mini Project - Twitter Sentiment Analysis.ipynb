{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xBtJw8A09DWD"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import log_loss"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read the Data from the Given excel file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WZWzjIaq9Phr"
      },
      "outputs": [],
      "source": [
        "# Reading the data from the given csv file\n",
        "data = pd.read_csv(\"/content/Twitter_Data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "_hfSUrIc90Se",
        "outputId": "354a2d37-cbc0-4e82-8768-da85e40435ed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-57ffa588-d3f0-495d-91e0-53b318e53eb8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>category</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>modi promised minimum government maximum gover...</td>\n",
              "      <td>Negative</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>talk nonsense continue drama vote modi</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>say vote modi welcome bjp told rahul main camp...</td>\n",
              "      <td>Positive</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57ffa588-d3f0-495d-91e0-53b318e53eb8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57ffa588-d3f0-495d-91e0-53b318e53eb8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57ffa588-d3f0-495d-91e0-53b318e53eb8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          clean_text  category  length\n",
              "0  modi promised minimum government maximum gover...  Negative      21\n",
              "1             talk nonsense continue drama vote modi   Neutral       6\n",
              "2  say vote modi welcome bjp told rahul main camp...  Positive      13"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Change our dependent variable to categorical. (0 to “Neutral,”-1 to “Negative”, 1 to “Positive”)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "z5ZaPnxy9ZOS"
      },
      "outputs": [],
      "source": [
        "# Changing the dependent variable to categorical\n",
        "data['category'] = data['category'].map({0: \"Neutral\", -1: \"Negative\", 1: \"Positive\"})"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Do Missing value analysisand drop all null/missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CBReh_ZU9rUs"
      },
      "outputs": [],
      "source": [
        "# Missing value analysis and dropping null/missing values\n",
        "data = data.dropna()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Do text cleaning. (remove every symbol except alphanumeric, transform all words to lower case, and remove punctuationand stopwords )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kiSvWhCi9tcu"
      },
      "outputs": [],
      "source": [
        "# Text cleaning\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]','',text) # remove punctuation\n",
        "    text = text.lower() # transform to lowercase\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = word_tokenize(text)\n",
        "    words = [word for word in words if word not in stop_words] # remove stopwords\n",
        "    text = \" \".join(words)\n",
        "    return text"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a new column and find the length of each sentence (how many words they contain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "k7Tcqi1S9weq"
      },
      "outputs": [],
      "source": [
        "data['clean_text'] = data['clean_text'].apply(clean_text)\n",
        "\n",
        "# Creating a new column for the length of each sentence\n",
        "data['length'] = data['clean_text'].apply(lambda x: len(str(x).split(\" \")))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split data into dependent(X) and independent(y) dataframe and Do operationson text data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KnXwlKl1-LOn"
      },
      "outputs": [],
      "source": [
        "# Splitting data into dependent(X) and independent(y) dataframe\n",
        "X = data['clean_text']\n",
        "y = data['category']\n",
        "\n",
        "# One-hot encoding for each sentence\n",
        "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X)\n",
        "X = tokenizer.texts_to_sequences(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mH1Itna0-gpg"
      },
      "outputs": [],
      "source": [
        "# Adding padding from the front side\n",
        "X = pad_sequences(X, padding='pre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xg-gWa7G-jhP"
      },
      "outputs": [],
      "source": [
        "# Building an LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=X.shape[1]))\n",
        "model.add(LSTM(units=64, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=64))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=3, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rP5ivRk6-lrD"
      },
      "outputs": [],
      "source": [
        "# Compiling the LSTM model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Dummy variable creation for the dependent variable\n",
        "y = pd.get_dummies(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pKkGyCh-onr",
        "outputId": "44f7cdfa-4c9d-4f05-d37d-70a1219dc0ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2460/2460 [==============================] - 118s 46ms/step - loss: 0.4127 - accuracy: 0.8563\n",
            "Epoch 2/10\n",
            "2460/2460 [==============================] - 111s 45ms/step - loss: 0.2997 - accuracy: 0.9086\n",
            "Epoch 3/10\n",
            "2460/2460 [==============================] - 113s 46ms/step - loss: 0.2712 - accuracy: 0.9148\n",
            "Epoch 4/10\n",
            "2460/2460 [==============================] - 111s 45ms/step - loss: 0.2406 - accuracy: 0.9222\n",
            "Epoch 5/10\n",
            "2460/2460 [==============================] - 111s 45ms/step - loss: 0.2091 - accuracy: 0.9307\n",
            "Epoch 6/10\n",
            "2460/2460 [==============================] - 112s 45ms/step - loss: 0.1796 - accuracy: 0.9397\n",
            "Epoch 7/10\n",
            "2460/2460 [==============================] - 111s 45ms/step - loss: 0.1492 - accuracy: 0.9499\n",
            "Epoch 8/10\n",
            "2460/2460 [==============================] - 112s 45ms/step - loss: 0.1251 - accuracy: 0.9576\n",
            "Epoch 9/10\n",
            "2460/2460 [==============================] - 112s 45ms/step - loss: 0.1028 - accuracy: 0.9660\n",
            "Epoch 10/10\n",
            "2460/2460 [==============================] - 113s 46ms/step - loss: 0.0844 - accuracy: 0.9721\n",
            "615/615 [==============================] - 8s 11ms/step\n"
          ]
        }
      ],
      "source": [
        "# Splitting the data into tests and train\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Normalizing the prediction as same as the original data\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_test = np.argmax(y_test.values, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = confusion_matrix(X_train,y_pred)\n",
        "print ('Confusion Matrix :')\n",
        "print(results)\n",
        "print ('Accuracy Score is',accuracy_score(X_train,y_pred ))\n",
        "print ('Classification Report : ')\n",
        "print (classification_report(X_train, y_pred))\n",
        "print('AUC-ROC:',roc_auc_score(X_train, y_pred))\n",
        "print('LOGLOSS Value is',log_loss(X_train, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJJ0vSD1-qsm",
        "outputId": "985b1621-c53c-409e-9100-16b3f32e86d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.82      0.81      4301\n",
            "           1       0.90      0.91      0.90      6641\n",
            "           2       0.90      0.88      0.89      8736\n",
            "\n",
            "    accuracy                           0.88     19678\n",
            "   macro avg       0.87      0.87      0.87     19678\n",
            "weighted avg       0.88      0.88      0.88     19678\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Printing the classification report\n",
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
